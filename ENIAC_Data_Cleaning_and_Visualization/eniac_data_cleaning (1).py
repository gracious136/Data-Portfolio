# -*- coding: utf-8 -*-
"""ENIAC_Data Cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGKIUr_-zImPr-PdwKEXs-h7tK5lprgi

# Importing the Libraries and loading the Data
"""

# Important libraries for the analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.float_format', lambda x: '%.2f' % x)
pd.set_option('display.max_rows', 1000)

# Creating a Funtion for a shareable link from Google
def gd_path(file_id):
    """Generate a shareable link from Google Drive file id."""
    return f"https://drive.google.com/uc?export=download&id={file_id}"


# Google Drive file ids
files_id = {
    "brands": "1m1ThDDIYRTTii-rqM5SEQjJ8McidJskD",
    "orderlines": "1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG",
    "orders": "1Vu0q91qZw6lqhIqbjoXYvYAQTmVHh6uZ",
    "products":"1afxwDXfl-7cQ_qLwyDitfcCx3u7WMvkU"
}

# Reading in the data
brands = pd.read_csv(gd_path(files_id['brands']), sep =',')
orderlines = pd.read_csv(gd_path(files_id['orderlines']), sep =',')
orders = pd.read_csv(gd_path(files_id['orders']), sep =',')
products = pd.read_csv(gd_path(files_id['products']), sep =',')

"""# Overview and investigating the Data

Performing Exploratory Data Analysis (EDA)

Here’s a description of each table and its columns:

+ orders.csv – Every row in this file represents an order.

> + order_id – a unique identifier for each order
+ created_date – a timestamp for when the order was created
+ total_paid – the total amount paid by the customer for this order, in euros
state
+ “Shopping basket” – products have been placed in the shopping basket
+ “Place Order” – the order has been placed, but is awaiting shipment details
+ “Pending” – the order is awaiting payment confirmation
+ “Completed” – the order has been placed and paid, and the transaction is completed.
+ “Cancelled” – the order has been cancelled and the payment returned to the customer.


+ orderlines.csv – Every row represents each one of the different products involved in an order.


> + id – a unique identifier for each row in this file
+ id_order – corresponds to orders.order_id
+ product_id – an old identifier for each product, nowadays not in use
+ product_quantity – how many units of that product were purchased on that order
+ sku – stock keeping unit: a unique identifier for each product
+ unit_price – the unitary price (in euros) of each product at the moment of placing that order
+ date – timestamp for the processing of that product

+ products.csv


> + sku – stock keeping unit: a unique identifier for each product
name – product name
+ desc – product description
+ in_stock – whether or not the product was in stock at the moment of the data extraction
+ type – a numerical code for product type
+ promo_price – promotional price, in euros

+ brands.csv


> + short – the 3-character code by which the brand can be identified in the first 3 characters of products.sku
+ long – brand name

# Data Cleaning
"""

# For Grace
brands_gr = brands.copy()
orders_gr = orders.copy()
orderlines_gr = orderlines.copy()
products_gr = products.copy()

product_name = list(products_gr.sku.unique())

orderlines_gr = orderlines_gr[orderlines_gr.sku.isin(product_name)]

"""## brands


"""

brands_gr.describe()

brands_gr[brands_gr['long'] == 'Mophie']

brands_gr[brands_gr['long'] == 'Apple']

brands_gr[brands_gr['long'] == 'Startech']

brands_gr[brands_gr['long'] == 'Jaybird']

brands_gr[brands_gr['long'] == 'Unknown']

brands_gr.loc[brands_gr['short'] == 'MUJ', 'long']= 'Mujjo'

brands_gr.loc[brands_gr['short'] == 'KEN', 'long']= 'Kensington'

# cleaning the brands table by removing the rows that have unknown

brands_gr = brands_gr.drop(brands_gr[brands_gr['long'] == 'Unknown'].index)

# cleaning the brands table by removing the rows that have CAD

brands_gr = brands_gr.drop(brands_gr[brands_gr['short'] == 'CAD'].index)

brands_gr.describe()

brands_gr.long.value_counts()

brands_gr

clean_brands = brands_gr.copy()

"""## orders table"""

orders_gr.shape

orders_gr = orders_gr.drop_duplicates()# no duplicated rows

orders_gr.isna().sum()

orders_gr['total_paid'] = pd.to_numeric(orders_gr['total_paid'])

orders_gr[orders_gr.total_paid.isna()==True] # what do we do? do we make the toatal_paid 0€ since their status is pending?
#or we replace it with the mean payment of the pending orders so that it does not affect the statistics. I dropped it

orders_gr = orders_gr.dropna(subset = 'total_paid')

orders_gr.loc[orders_gr.state=='Pending']

orders_gr['created_date']=pd.to_datetime(orders_gr['created_date'])

orders_gr['date'] =pd.to_datetime(orders_gr['created_date']).dt.date

orders_gr['time'] =pd.to_datetime(orders_gr['created_date']).dt.time

orders_gr['order_year'] =pd.to_datetime(orders_gr['created_date']).dt.year

orders_gr['order_month'] =pd.to_datetime(orders_gr['created_date']).dt.strftime('%B') #or dt.month_name()

orders_gr['order_weekday'] =pd.to_datetime(orders_gr['created_date']).dt.day_name()

orders_gr['order_day'] =pd.to_datetime(orders_gr['created_date']).dt.day

orders_gr['total_paid'] = round(orders_gr['total_paid'], 2)

orders_gr

clean_orders = orders_gr.copy()

"""## products"""

products_gr.duplicated().sum()

products_gr.shape

products_gr = products_gr.drop_duplicates()

products_gr.shape

products_gr.isna().sum()

products_gr = products_gr.dropna(subset='price')

products_gr = products_gr.dropna(subset='desc')

products_gr.price.str.contains('^\d{,}.\d{,}$').value_counts(normalize=True)

products_gr = products_gr.loc[products_gr.price.str.contains('^\d{,}.\d{,}$')==True]

products_gr.shape

products_gr.promo_price.str.contains('^\d{,}.\d{,}$').value_counts(normalize=True)

new_promo = []

for promo, price in zip(products_gr['promo_price'], products_gr['price']):
    price = str(price)
    promo = str(promo)

    if "." in price and price.count('.') == 1:
        promo = promo.replace(".", "")
        promo = promo[:price.index(".")] + "." + promo[price.index("."):]
        if round(float(promo)) > round(float(price)):
            promo = promo.replace(".", "")
            promo = promo[:price.index(".")-1] + "." + promo[price.index(".")-1:]

    if price != 'nan' and price.count('.') == 0:
        promo = promo.replace(".", "")
        promo = promo[:len(price)] + "." + promo[len(price):]
        if round(float(promo)) > round(float(price)):
            promo = promo.replace(".", "")
            promo = promo[:len(price)-1] + "." + promo[len(price)-2:]
    new_promo.append(promo)

len(new_promo)

products_gr['new_promo'] =new_promo

products_gr['price'] = pd.to_numeric(products_gr['price'])

products_gr['price'] = round(products_gr['price'].astype(float), 2)

products_gr['new_promo'] = pd.to_numeric(products_gr['new_promo'])

products_gr['new_promo'] = round(products_gr['new_promo'].astype(float), 2)

products_gr

products_gr = products_gr.loc[products_gr['price'] >= products_gr['new_promo']]

products_gr['product_brand'] = products_gr.sku.str.extract('(^\w{3})') #or products_gr['product_brand'] = products_gr.sku.str[0:3]

products_gr['discount'] = products_gr.apply(lambda record: round(((record['price'] - record['new_promo']) / record['price'])*100, 2), axis=1)
#or
# products_gr['discount'] = round(((products_gr['price'] - products_gr['new_promo']) / products_gr['price']), 2)

products_gr['discount'].plot(kind='hist');

products_gr[products_gr['discount']<=70].shape

products_gr[products_gr['discount']>70].count()

#products_gr = products_gr.loc[~(products_gr['discount']>70)]

type_categories = {'8696':'accessories', '13855401': 'keyboard', '1387':'mouse', '1230':'accessories', '1364':'computer', '1325':'accessories', '5384':'audio',
 '1334':'accessories', '13005399': 'accessories', '12995397': 'accessories', '11865403': 'phone_accessories', '13955395' :'accessories', '1216':'accessories',
 '12355400': 'accessories', '1276' : 'computer_accessories', '11905404':'others', '12635403':'accessories', '12755395':'accessories', '13835403':'computer_accessories',
 '1296':'computer', '12285400': 'phone_accessories', '1229':'accessories', '11935397':'storage', '12655397':'storage', '1404':'others', '101781405':'others',  '4259':'audio', '14035403':'phone',
 '12085400':'accessories', '1282':'computer', '12175397':'storage', '1424':'media', '9094':'security', '1405':'computer_accessories',  '57445397':'storage', '14305406':'computer_accessories',
 '10142':'battery','12645406':'phone_accessories', '10230':'computer_accessories', '12215397':'storage', '11821715':'audio',  '13555403':'phone_accessories', '14365395':'phone_accessories',
 '5405':'phone_accessories', '5395':'electrical_appliances', '5398':'audio', '21485407':'phone_accessories', '20642062':'storage', '1280':'others', '1433':'storage', '1515':'battery',
 '5720':'phone_accessories', '1298':'storage', '13615399':'electrical_appliances', '12585395':'computer_accessories',  '1392':'computer_accessories', '1231':'others', '15435404':'computer_accessories',
 '1375':'computer_accessories', '42945397':'storage', '12141714':'computer', '54025401':'accessories', '12575403':'keyboard', '21535407':'accessories', '1416':'others', '24215399':'watch_accessories',
 '11434':'computer_accessories', '2434':'watch_accessories', '2449':'watch_accessories',  '2425':'watch_accessories', '13621714':'phone', '24861714':'phone', '24821716':'phone',
 '54864259':'tv_accessories', '1714':'phone', '51601716':'phone', '51871714':'computer', '5403':'computer_accessories', '54085407':'computer_accessories', '24885185':'watch', '24895185':'watch',
 '5407':'phone_accessories', '5406':'others', '5404':'others', '85641716':'phone', '42931714':'computer', '24811716':'phone', '85651716':'phone', '2158':'computer', '51882158':'computer',
 '5401':'keyboard', '12051714':'others', '5399':'phone_accessories', '1716':'phone', '21622158':'computer', '12031714':'computer', '51861714':'computer', '21571716':'phone', '106431714':'phone',
 '21632158':'computer', '79201715':'audio', '21561716':'phone', '51902158':'computer', '113291716':'phone', '113281716':'phone', '113271716':'phone', '113851714':'computer', '11859':'others',
 '118692158':'computers', '51912158':'computer', '113464259':'audio', '12282':'watch_accessories'}

not_found = ['5,49E+11', '1,44E+11', '1,46E+11', '2,17E+11', '5,74E+15', '5,44E+11', '1,02E+12', '5,72E+15', '5,39E+11', '2,16E+11', '5,45E+15']

products_gr['product_category'] = products_gr['type'].astype(str).map(type_categories).fillna('Unknown')

products_gr.loc[((products_gr['product_category']=='accessories') & (products_gr['desc'].str.contains('imac|pc|macbook|mac', case=False))), 'product_category'] = 'computer_accessories'
products_gr.loc[((products_gr['product_category']=='accessories') & (products_gr['desc'].str.contains('iphone', case=False))), 'product_category'] = 'phone_accessories'
products_gr.loc[((products_gr['product_category']=='computers') & (products_gr['desc'].str.contains('ipad', case=False))), 'product_category'] = 'tablets'
products_gr.loc[((products_gr['product_category']=='phone') & (products_gr['desc'].str.contains('ipad', case=False))), 'product_category'] = 'tablets'
products_gr.loc[((products_gr['product_category']=='Unknown') & (products_gr['desc'].str.contains('laptop|computer|imac|macbook', case=False))), 'product_category'] = 'computers'
products_gr.loc[((products_gr['product_category']=='Unknown') & (products_gr['desc'].str.contains('case', case=False))), 'product_category'] = 'phone_accessories'
products_gr.loc[((products_gr['product_category']=='Unknown') & (products_gr['desc'].str.contains('repair|diagnosis|labor', case=False))), 'product_category'] = 'insurance'
products_gr.loc[((products_gr['product_category']=='storage') & (products_gr['desc'].str.contains('monitor', case=False))), 'product_category'] = 'computers'
products_gr.loc[((products_gr['product_category']=='storage') & (products_gr['desc'].str.contains('laptop', case=False))), 'product_category'] = 'computers'
products_gr.loc[((products_gr['product_category']=='storage') & (products_gr['desc'].str.contains('smartwatch', case=False))), 'product_category'] = 'watch'
products_gr.loc[((products_gr['product_category']=='storage') & (products_gr['name'].str.contains('apple iphone', case=False))), 'product_category'] = 'phone'
products_gr.loc[((products_gr['product_category']=='storage') & (products_gr['name'].str.contains('apple ipad', case=False))), 'product_category'] = 'tablets'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['desc'].str.contains('smartwatch|Smart Watch', case=False))), 'product_category'] = 'watch'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['name'].str.contains('power wireless sensor', case=False))), 'product_category'] = 'electrical_accessories'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['name'].str.contains('motion sensor', case=False))), 'product_category'] = 'security'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['desc'].str.contains('baby monitor', case=False))), 'product_category'] = 'security'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['desc'].str.contains('baby monitor', case=False))), 'product_category'] = 'security'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['desc'].str.contains('selfie', case=False))), 'product_category'] = 'phone_accessories'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['name'].str.contains('smartwatch', case=False))), 'product_category'] = 'watch'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['desc'].str.contains('warranty', case=False))), 'product_category'] = 'insurance'
products_gr.loc[((products_gr['product_category']=='others') & (products_gr['name'].str.contains('apple ipad', case=False))), 'product_category'] = 'tablets'

products_gr.loc[products_gr['product_category'] == 'keyboard', 'product_category'] = 'computer_accessories'
products_gr.loc[products_gr['product_category'] == 'mouse', 'product_category'] = 'computer_accessories'
products_gr.loc[products_gr['product_category'] == 'audio', 'product_category'] = 'multimedia'
products_gr.loc[products_gr['product_category'] == 'media', 'product_category'] = 'multimedia'
products_gr.loc[products_gr['product_category'] == 'tv_accessories', 'product_category'] = 'multimedia'
products_gr.loc[products_gr['product_category'] == 'electrical_appliances', 'product_category'] = 'electrical_accessories'
products_gr.loc[products_gr['product_category'] == 'battery', 'product_category'] = 'electrical_accessories'

products_gr.loc[(products_gr['product_category'].str.contains('accessories', case=False)), 'product_category'] = 'accessories'
products_gr.loc[(products_gr['product_category'].str.contains('insurance', case=False)), 'product_category'] = 'services'
products_gr.loc[(products_gr['product_category'].str.contains('multimedia', case=False)), 'product_category'] = 'media'
products_gr.loc[(products_gr['product_category'].str.contains('phone', case=False)), 'product_category'] = 'phones'
products_gr.loc[(products_gr['product_category'].str.contains('unknown', case=False)), 'product_category'] = 'accessories'
products_gr.loc[(products_gr['product_category'].str.contains('watch', case=False)), 'product_category'] = 'watches'

products_gr

products_gr.product_category.unique()

clean_products = products_gr.copy()

# products table is complete

"""## orderlines"""

orderlines_gr

orderlines_gr.shape

orderlines_gr.duplicated().sum()

orderlines_gr.isna().sum()

orderlines_gr.info()

import re

def convert_price(record):

  if re.match(r'^\d+\.\d{1,3}$', record):
    return record

  else:
    parts = record.split('.')
    if len(parts) == 3:
      return float(record.split('.')[0] + record.split('.')[1] + '.' + record.split('.')[2])
    else:
      return record

orderlines_gr['unit_price'] = orderlines_gr['unit_price'].apply(convert_price)

orderlines_gr.unit_price.str.contains('^\d{,}\.\d{,3}$').value_counts(normalize=True)

orderlines_gr = orderlines_gr.loc[orderlines_gr['unit_price'].str.match(r'^\d+\.\d{1,3}$', na=False)] # or # orderlines_gr.loc[orderlines_gr.unit_price.str.contains('^\d{,}\.\d{,3}$') == True]

orderlines_gr.shape

orderlines_gr['unit_price'] = pd.to_numeric(orderlines_gr['unit_price'])

orderlines_gr

clean_orderlines = orderlines_gr.copy()

"""## Data merging"""

# to selct an create a giant table
# but first clean the orders and select the data we want

clean_products.info()

clean_orderlines.info()

clean_orders.info()

clean_brands.info()

"""### Grace: create the giant table for analysis

first select the data that is needed from each table
"""

clean_orderlines

clean_orderlines.id_order.nunique()

clean_orderlines = clean_orderlines[clean_orderlines.sku.isin(list(clean_products.sku.unique()))]

clean_orderlines.shape

clean_orders.state.value_counts()

def completed_orders(record):
  return record.loc[record['state'].isin(['Completed'])]

clean_orders_completed = clean_orders.pipe(completed_orders)

clean_orders_completed.info()

clean_orderlines.info()

def common_orders(record1, record2, key1:str, key2:str):

  return record1.merge(record2, how = 'inner', left_on =key1, right_on = key2)

common_id_list = list(common_orders(clean_orders_completed, clean_orderlines, 'order_id', 'id_order').id_order)

clean_orders_completed_id = clean_orders_completed[clean_orders_completed['order_id'].isin(common_id_list)]

clean_orderlines_id = clean_orderlines[clean_orderlines['id_order'].isin(common_id_list)]

len(clean_orderlines_id.id_order.unique())

len(clean_orders_completed_id.order_id.unique())

len(clean_orders_completed_id.order_id)

len(clean_orderlines_id.id_order)

clean_orders_completed_id

clean_orderlines_id

pay_diff = clean_orders_completed_id.groupby(['created_date','date','order_year','order_month','order_day','time','order_id'], as_index = False)['total_paid'].sum()\
.merge(clean_orderlines_id, how = 'inner', left_on ='order_id', right_on = 'id_order')

pay_diff

pay_diff['total_cost'] = pay_diff['unit_price'] * pay_diff['product_quantity']

pay_diff['cost_diff'] = pay_diff['total_paid'] - pay_diff['total_cost']

pay_diff['cost_diff'].mean().round(2)

pay_diff['cost_diff'].describe()

q1 = pay_diff['cost_diff'].quantile(0.25)
q3 = pay_diff['cost_diff'].quantile(0.75)

iqr = q3 - q1

pay_diff_w_outliers = pay_diff.loc[(pay_diff['cost_diff'] >= (q1 - 1.5*iqr)) & (pay_diff['cost_diff'] <= (q3 + 1*iqr))]

pay_diff_w_outliers['cost_diff'].mean()

pay_diff_w_outliers['cost_diff'].hist()

pay_diff_w_outliers[pay_diff_w_outliers['cost_diff']>50]

pay_diff_w_outliers.describe()

pay_diff_w_outliers

"""### All Sales Data"""

all_data = pay_diff_w_outliers.merge(
    clean_products,
    how = 'inner',
    right_on = 'sku',
    left_on = 'sku',
    suffixes = ('_orders', '_products')
).merge(
    clean_brands,
    how = 'inner',
    left_on = 'product_brand',
    right_on = 'short'
).dropna()

all_data.loc[all_data['product_category'] == 'computer', 'product_category'] = 'computers'

all_data.shape

all_data.columns

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

all_data.to_csv('/content/drive/MyDrive/WBS/clean_combined_data', index=False)